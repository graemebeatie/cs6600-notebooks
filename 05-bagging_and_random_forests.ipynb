{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05: Bagging and random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mylib as my"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of ensemble methods to to reduce bias and/or variance help prevent overfitting. In this notebook we look at two ensemble methods: bagging and random forests.\n",
    "\n",
    "## Bootstrap samples\n",
    "Let's start by seeing how we can draw a bootstrap sample given a dataset $D$. A bootstrap sample is a sample drawn randomly with replacement from the given dataset such that the size of the sample is the same as the size of the original dataset. That means some examples will show up multiple times in the drawn sample.\n",
    "\n",
    "In the example below, we are using a subset of the car dataset with classes indicating whether the car is in acceptable or unacceptable condition. The description of the original car dataset can be found at [this page](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unacc    384\n",
      "acc      384\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/ua_car.csv')\n",
    "ds = my.DataSet(df, y=True)\n",
    "print(df.iloc[:,-1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    buying maintenance  doors persons luggage safety      y\n",
      "196  vhigh         low      3       2     med   high  unacc\n",
      "160   high         low  5more       4     med    low  unacc\n",
      "479   high        high      4    more     med   high    acc\n",
      "140    low         low      2       2     med   high  unacc\n",
      "291  vhigh       vhigh      3    more   small    low  unacc\n",
      "..     ...         ...    ...     ...     ...    ...    ...\n",
      "569    med       vhigh      2    more     big    med    acc\n",
      "296   high         med  5more       2   small    low  unacc\n",
      "476   high        high      4       4     big   high    acc\n",
      "637    med         med      2       4   small   high    acc\n",
      "189  vhigh         low      4       4   small    low  unacc\n",
      "\n",
      "[576 rows x 7 columns]\n",
      "    buying maintenance  doors persons luggage safety      y\n",
      "627    med        high  5more       4     med    med    acc\n",
      "384  vhigh         med      2       4   small   high    acc\n",
      "324  vhigh       vhigh      3       2     med   high  unacc\n",
      "100    low         low  5more    more     med    low  unacc\n",
      "362    med        high      3       4     med    low  unacc\n",
      "..     ...         ...    ...     ...     ...    ...    ...\n",
      "225   high        high  5more       4     med    low  unacc\n",
      "308    med        high  5more       2     med   high  unacc\n",
      "349   high         med  5more       4     med    low  unacc\n",
      "740    low        high  5more       4   small    med    acc\n",
      "516   high         med      4    more     big    med    acc\n",
      "\n",
      "[192 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "train, test = ds.train_test_split(test_portion=.25, shuffle=True)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above training set, we can draw a bootstrap sample like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maintenance</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>luggage</th>\n",
       "      <th>safety</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>med</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>low</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>low</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>high</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    buying maintenance  doors persons luggage safety      y\n",
       "580    med       vhigh      4       4   small   high    acc\n",
       "714    low       vhigh  5more    more     big   high    acc\n",
       "162  vhigh         low      3       2   small    med  unacc\n",
       "622    med        high      4    more     med    med    acc\n",
       "712    low       vhigh  5more    more     med   high    acc\n",
       "..     ...         ...    ...     ...     ...    ...    ...\n",
       "21   vhigh        high  5more       2     med   high  unacc\n",
       "124   high       vhigh      4       4     big    med  unacc\n",
       "68   vhigh        high      4       4   small    low  unacc\n",
       "466   high        high      3       4     big   high    acc\n",
       "162  vhigh         low      3       2   small    med  unacc\n",
       "\n",
       "[576 rows x 7 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indexes = np.random.randint(0, train.N, size=train.N)\n",
    "# print(sample_indexes)\n",
    "bootstrap_sample = train.examples.iloc[sample_indexes, :]\n",
    "bootstrap_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "of which:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.15% are unique examples\n",
      "37.85% are repeated examples\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.2%}\".format(\n",
    "    pd.unique(bootstrap_sample.index).shape[0] / len(bootstrap_sample)), 'are unique examples')\n",
    "print(\"{:.2%}\".format(\n",
    "    1 - pd.unique(bootstrap_sample.index).shape[0] / len(bootstrap_sample)), 'are repeated examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, it's useful to be able to identify the examples that are included in a given sample and those that aren't. Here are two functions for doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examples_in_sample(examples, sample):\n",
    "    return examples[examples.index.isin(sample.index)]\n",
    "\n",
    "# can i just turn this into the in bag or out of bag?\n",
    "def examples_not_in_sample(examples, sample):\n",
    "    return examples[~examples.index.isin(sample.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the examples from the training set what are in the above bootstrap sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maintenance</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>luggage</th>\n",
       "      <th>safety</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>low</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>low</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>med</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    buying maintenance  doors persons luggage safety      y\n",
       "479   high        high      4    more     med   high    acc\n",
       "140    low         low      2       2     med   high  unacc\n",
       "352    low         med  5more       2     med    low  unacc\n",
       "695    low       vhigh      4       4   small   high    acc\n",
       "707    low       vhigh  5more       4     med   high    acc\n",
       "..     ...         ...    ...     ...     ...    ...    ...\n",
       "569    med       vhigh      2    more     big    med    acc\n",
       "296   high         med  5more       2   small    low  unacc\n",
       "476   high        high      4       4     big   high    acc\n",
       "637    med         med      2       4   small   high    acc\n",
       "189  vhigh         low      4       4   small    low  unacc\n",
       "\n",
       "[358 rows x 7 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_in_sample(train.examples, bootstrap_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the examples from the training set that are not in the above bootstrap sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(examples_not_in_sample(train.examples, bootstrap_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "The simplest form of ensemble methods is called **bagging** which stands for **bootstrap aggregation**. The idea is simple:\n",
    "* take $T$ bootstrap samples from the given dataset\n",
    "* for each bootstrap sample, train a decision tree DT\n",
    "* the predicted label of an unseen example is the average(for regression problems) or the plurality vote (for classification problems) of all the output predicted by all the trained $T$ trees.\n",
    "\n",
    "Here is a simple implementation of bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagger:\n",
    "    def __init__(self, dataset, nTrees):\n",
    "        self.ds = dataset\n",
    "        self.nTrees = nTrees\n",
    "        self.classifiers = []\n",
    "        self.samples = []\n",
    "        self.make_trees()\n",
    "\n",
    "    def make_trees(self):\n",
    "        indexes = np.random.randint(0, self.ds.N,(self.ds.N,self.nTrees))\n",
    "        for i in range(self.nTrees):\n",
    "            # Create bootstrap samples one for each tree\n",
    "            self.samples.append(self.ds.examples.iloc[indexes[:, i], :])\n",
    "\n",
    "            # Build classifiers\n",
    "            self.classifiers.append(my.DecisionTreeClassifier(my.DataSet(self.samples[i])))\n",
    "\n",
    "    def predict(self, unseen):\n",
    "        \"\"\"\n",
    "        Returns the most probable label (or class) for each unseen input. The\n",
    "        unseen needs to be a data series with the same features (as indexes) as the \n",
    "        training data. It can also be a data frame with the same features as \n",
    "        the training data.\n",
    "        \"\"\"\n",
    "        if unseen.ndim == 1:\n",
    "            classes = np.array([ dt.predict(unseen) for dt in self.classifiers ])\n",
    "            classes = classes[classes != None]\n",
    "            return st.mode(classes).mode[0]\n",
    "        \n",
    "        else:\n",
    "            return np.array([self.predict(unseen.iloc[i,:]) for i in range(len(unseen))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests\n",
    "Bagging is not exclusive to decision trees; it can be used with other models. Random forests is bagging applied exclusively to decision trees. In addition to obtaining $T$ random bootstrap samples, it also requires what is sometimes called **feature bagging**. Feature bagging requires that only a randomly selected subset of the features is considered at each node during the construction of the decision tree. \n",
    "\n",
    "That means we need to modify our implementation of the decision tree such that it takes a numeric parameter named `nFeatures` which defaults to 0. If `nFeatures` is 0, then the tree functions as normal. If not, it picks this many features randomly and only consider the best of those during the construction of the tree. The provided `my.DecisionTreeClassifier` class already has these changes.\n",
    "\n",
    "For prediction, a plurality vote of the $T$ predicted labels is returned. Here is a simple implementing of random forests. Think about the similarities and differences between these too classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, dataset, nTrees, nFeatures=0):\n",
    "        self.ds = dataset\n",
    "        self.nTrees = nTrees\n",
    "        self.nFeatures = nFeatures\n",
    "        self.classifiers = []\n",
    "        self.samples = []\n",
    "        self.make_forest()\n",
    "\n",
    "    def make_forest(self):\n",
    "        indexes = np.random.randint(0, self.ds.N,(self.ds.N,self.nTrees))\n",
    "        for i in range(self.nTrees):\n",
    "            # Create bootstrap samples one for each tree\n",
    "            self.samples.append(self.ds.examples.iloc[indexes[:, i], :])\n",
    "\n",
    "            # Build classifiers\n",
    "            self.classifiers.append(my.DecisionTreeClassifier(my.DataSet(self.samples[i]), nFeatures=self.nFeatures))\n",
    "\n",
    "    def predict(self, unseen):\n",
    "        \"\"\"\n",
    "        Returns the most probable label (or class) for each unseen input. The\n",
    "        unseen needs to be a data series with the same features (as indexes) as the \n",
    "        training data. It can also be a data frame with the same features as \n",
    "        the training data.\n",
    "        \"\"\"\n",
    "        if unseen.ndim == 1:\n",
    "            classes = np.array([ dt.predict(unseen) for dt in self.classifiers ])\n",
    "            classes = classes[classes != None]\n",
    "            return st.mode(classes,keepdims=True).mode[0]\n",
    "        \n",
    "        else:\n",
    "            return np.array([self.predict(unseen.iloc[i,:]) for i in range(len(unseen))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89  2]\n",
      " [ 4 97]]\n",
      "Decistion tree accuracy:  0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\graem\\AppData\\Local\\Temp\\ipykernel_5408\\1636490916.py:28: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  return st.mode(classes).mode[0]\n",
      "c:\\Users\\graem\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\graem\\AppData\\Local\\Temp\\ipykernel_5408\\1636490916.py:28: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  return st.mode(classes).mode[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89  2]\n",
      " [11 90]]\n",
      "Bagger accuracy:  0.9322916666666666\n",
      "[[91  0]\n",
      " [13 88]]\n",
      "Random forests accuracy:  0.9322916666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\graem\\AppData\\Local\\Temp\\ipykernel_5408\\1147172297.py:29: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  return st.mode(classes).mode[0]\n",
      "c:\\Users\\graem\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\graem\\AppData\\Local\\Temp\\ipykernel_5408\\1147172297.py:29: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  return st.mode(classes).mode[0]\n"
     ]
    }
   ],
   "source": [
    "dt = my.DecisionTreeClassifier(train)\n",
    "cm = my.confusion_matrix(test.target, dt.predict(test.examples.iloc[:,:-1]))\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "# print(test.examples.iloc[1,:])\n",
    "print(cm)\n",
    "print('Decistion tree accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "bg = Bagger(train, 20)\n",
    "cm = my.confusion_matrix(test.target, bg.predict(test.examples.iloc[:,:-1]))\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "\n",
    "print(cm)\n",
    "print('Bagger accuracy: ', accuracy)\n",
    "\n",
    "rf = RandomForest(train, 20, nFeatures=3)\n",
    "cm = my.confusion_matrix(test.target, rf.predict(test.examples.iloc[:,:-1]))\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "\n",
    "print(cm)\n",
    "print('Random forests accuracy: ', accuracy)\n",
    "\n",
    "# print(rf.classifiers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should try different values for `nTrees` and `nFeatures`. These variables are considered hyperparameters, and cross-validation can be used to determine the best values for them. Common values for `nFeatures` are $\\sqrt{m}$ and $log_2(m)$ where $m$ is the number of features.\n",
    "\n",
    "## Out of bag score\n",
    "Another way of testing random forests is to calculate the so-called **out-of-bag** score. Such a score does not require splitting the dataset into a training and test sets. One way to calculate it is to identify for each example $x$ in the dataset the list of trees that are trained using samples that do not include it; let's call this list of trees $D_x$. We then call the `predict` method on each tree of $D_x$ to get the list of predicted classes for each of of these out of bag $x$ examples; let's call this list of classes $C_x$. Finally we find the class in $C_x$ that repeats the most and report it as the predicted class of $x$; let's call it $h_x$.\n",
    "\n",
    "Doing this for each example in the dataset gives us an array of predicted classes, which we can compare against the actual target classes of these examples. Using the confusion matrix we can report the accuracy as the out of bag score.\n",
    "\n",
    "Notice that the above implementations of `Bagger` and `RandomForest` already give you access to the bootstrap samples and the classifiers that are trained on them. You can use that to find out what sample does not include a given example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHALLENGE\n",
    "Write a function that calculates the out of bag score as described above given three arguments: a dataset, number of trees (`nTrees`), and number of features (`nFeatures`). The function should use these arguments to create a random forest object to use for calculating this score.\n",
    "\n",
    "Test and report the out of bag scores for the whole car dataset and for when `nTrees` is 10, 15, and 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_of_bag_score(data, nTrees, nFeatures):\n",
    "\n",
    "    treesNotTrainedWithList = []\n",
    "    # create the random forest object using in bag dataset\n",
    "    rf = RandomForest(data, nTrees, nFeatures)\n",
    "\n",
    "    # for each example in the dataset go through every classifier to see if it was trained or not by it\n",
    "    for i in range(rf.ds.N):\n",
    "\n",
    "        out_of_bag_arr = np.zeros(nTrees) # create an array for each example for trees that it is not in\n",
    "        # go through each list of indices used\n",
    "        for j in range(nTrees):\n",
    "            \n",
    "            # if index is not in the samples used index then it is marked as a 1\n",
    "            not_in_df = examples_not_in_sample(rf.ds.examples, rf.samples[j])\n",
    "\n",
    "            if i in not_in_df.index:\n",
    "                out_of_bag_arr[j] = 1\n",
    "        # put example out of bag array in not trained list  \n",
    "        treesNotTrainedWithList.append(out_of_bag_arr) \n",
    "    \n",
    "    # predict the out of bag values using their same classifier\n",
    "    out_of_bag_mode_list = []\n",
    "\n",
    "    # go through each predicted sample\n",
    "    for k in range(rf.ds.N):\n",
    "\n",
    "        # call predict on each value \n",
    "        out_of_bag_preds_list = []\n",
    "        for l in range(nTrees):\n",
    "            \n",
    "            # print(treesNotTrainedWithList[k][l])\n",
    "            if treesNotTrainedWithList[k][l] == 1:\n",
    "                # predict using the lth tree if it was an out of bag value\n",
    "                predVal = rf.classifiers[l].predict(data.examples.iloc[k,:-1])\n",
    "                out_of_bag_preds_list.append(predVal)\n",
    "  \n",
    "        # append the mode of the predicted values \n",
    "        if len(out_of_bag_preds_list) > 0:\n",
    "            # it doesn't like this \n",
    "            pred_mode = st.mode(out_of_bag_preds_list,keepdims=True).mode[0]\n",
    "           \n",
    "\n",
    "        # if the value was always in the sample just use what the full model would've predicted\n",
    "        else:\n",
    "            pred_mode = rf.predict(data.examples.iloc[k,:-1])\n",
    "\n",
    "        out_of_bag_mode_list.append(pred_mode)\n",
    "\n",
    "    preds = np.array(out_of_bag_mode_list)         \n",
    "    cm = my.confusion_matrix(data.target, preds)\n",
    "\n",
    "    return cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out ntrees = 10, 15, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\graem\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\graem\\AppData\\Local\\Temp\\ipykernel_5408\\3132053637.py:41: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  pred_mode = st.mode(out_of_bag_preds_list,keepdims=True).mode[0]\n",
      "C:\\Users\\graem\\AppData\\Local\\Temp\\ipykernel_5408\\417025228.py:29: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  return st.mode(classes,keepdims=True).mode[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[370  14]\n",
      " [ 33 351]]\n",
      "Out of bag score for nTrees = 10:  0.9388020833333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\graem\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\graem\\AppData\\Local\\Temp\\ipykernel_5408\\3132053637.py:41: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  pred_mode = st.mode(out_of_bag_preds_list,keepdims=True).mode[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[378   6]\n",
      " [ 32 352]]\n",
      "Out of bag score for nTrees = 15:  0.9505208333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\graem\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\graem\\AppData\\Local\\Temp\\ipykernel_5408\\3132053637.py:41: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  pred_mode = st.mode(out_of_bag_preds_list,keepdims=True).mode[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[376   8]\n",
      " [ 34 350]]\n",
      "Out of bag score for nTrees = 20:  0.9453125\n"
     ]
    }
   ],
   "source": [
    "score10_cm = out_of_bag_score(ds,10,4)\n",
    "accuracy10 = np.trace(score10_cm) / np.sum(score10_cm)\n",
    "\n",
    "print(score10_cm)\n",
    "print('Out of bag score for nTrees = 10: ', accuracy10)\n",
    "\n",
    "score15_cm = out_of_bag_score(ds,15,4)\n",
    "accuracy15 = np.trace(score15_cm) / np.sum(score15_cm)\n",
    "\n",
    "print(score15_cm)\n",
    "print('Out of bag score for nTrees = 15: ', accuracy15)\n",
    "\n",
    "score20_cm = out_of_bag_score(ds,20,4)\n",
    "accuracy20 = np.trace(score20_cm) / np.sum(score20_cm)\n",
    "\n",
    "print(score20_cm)\n",
    "print('Out of bag score for nTrees = 20: ', accuracy20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1396ec6b7005801cec9bc3cb765d7dcea11e93e871102b375b495cb1f8570a45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
